
# Agents Configuration & Registration

## Begriffe

- **Agent**: Ausf√ºhrbare LLM-Komponente mit eigener Logik
- **Skill**: Wiederverwendbare F√§higkeit eines Agenten
- **Plugin**: Paket aus Agent + Skills + Konfiguration

Diese Definitionen sorgen f√ºr Klarheit und vermeiden Missverst√§ndnisse bei neuen Nutzern.

Dieses Dokument beschreibt, wie Agenten f√ºr den OpenCode Manager und kompatible Plugin-Systeme in diesem Workspace hinzugef√ºgt, konfiguriert und registriert werden.

## Zweck

Agenten sind modulare Komponenten, die spezifische F√§higkeiten oder Automatisierungen f√ºr LLM-basierte Systeme bereitstellen. F√ºr die Funktion von Plugins ist die korrekte Registrierung und Platzierung der Agenten-Dateien erforderlich.

## Allgemeine Schritte

1. **Agenten-Paket/Implementierung beschaffen, das installiert werden soll.**
2. **Den Anweisungen im Plugin- oder Agenten-Repository folgen (siehe unten f√ºr Links/Beispiele).**
3. **Erforderliche `skills/`- oder `agents/`-Ordner an die richtige Stelle kopieren.**

**Standardpfade (empfohlen):**

- Agenten: `/bkg/workspace/agents/`
- Skills: `/bkg/workspace/skills/`
- Plugins: `/bkg/workspace/plugins/`

*Hinweis: Diese Pfade k√∂nnen je nach Plugin abweichen.*

1. **Falls der Agent in `opencode.json` oder einer anderen Konfiguration registriert werden muss, den detaillierten Hinweisen im README oder installation.md des Plugins folgen.**

**Minimalbeispiel f√ºr Agenten-Registrierung (`opencode.json`):**

```json
{
 "agents": {
  "mem": {
   "path": "./agents/opencode-mem",
   "enabled": true,
   "provider": "nvidia",
   "model": "meta/llama3-8b-instruct"
  }
 }
}
```

## Referenzen & Beispiel-Repositories

- [Oh-My-OpenCode Agent Guide](https://github.com/code-yeongyu/oh-my-opencode/blob/master/docs/guide/installation.md) ‚Äì Hauptagent-Manager, unterst√ºtzt Multi-Provider (z.B. Nvidia, Anthropic, OpenAI), CLI-Installation (`bunx oh-my-opencode install`), zentrale Agenten- und Skills-Registrierung.
- [OpenCode Model Announcer](https://github.com/ramarivera/opencode-model-announcer) ‚Äì Automatisiert Modell- und Agentenank√ºndigungen im OpenCode-√ñkosystem, einfache Installation via Plugin-Registrierung.
- [Opencode Mem](https://github.com/tickernelz/opencode-mem) ‚Äì Persistente Memory/Notiz-Agenten, ben√∂tigt SQLite, Installation via Plugin-Registrierung und ggf. Datenbank-Setup.
- [plannotator](https://github.com/backnotprop/plannotator) ‚Äì Plantasks- und Annotation-Agent, Integration √ºber OpenCode-Plugins, CLI- und API-Support.
- [opencode-workspace](https://github.com/kdcokenny/opencode-workspace) ‚Äì Workspace-Management-Agent, Installation via OCX-Registry und Plugin-Registrierung.
- [opencode-worktree](https://github.com/kdcokenny/opencode-worktree) ‚Äì Worktree/Branch-Management-Agent, OCX-Registry-Integration erforderlich.
- [opencode-scheduler](https://github.com/different-ai/opencode-scheduler) ‚Äì Zeit- und Task-Scheduler-Agent, Plugin-Installation, unterst√ºtzt geplante Agentenaktionen.
- [daytona](https://github.com/jamesmurdza/daytona) ‚Äì Externer Sandbox/Dev-Umgebungs-Agent, nicht nativ f√ºr OpenCode, ggf. externe Integration n√∂tig.

---

## Nvidia NIM Modelle

Dieser Abschnitt beschreibt die Integration und Nutzung der 32 Nvidia NIM Modelle im OpenCode Manager Workspace (Stand: 2026-01-30).

**Provider:** `nvidia`

**Hinweis:** Verf√ºgbarkeit und Modellnamen k√∂nnen sich seitens NVIDIA √§ndern.

**Authentifizierung:**

- Setze die Umgebungsvariable `NVIDIA_API_KEY` mit deinem Schl√ºssel (z.B. `nvapi-FAKE-KEY-EXAMPLE-DO-NOT-USE`).

‚ö†Ô∏è **Beispiel-Key ‚Äì niemals echte API-Keys committen oder ver√∂ffentlichen!**

- F√ºge den Provider `nvidia` in deiner `opencode.json` hinzu:

```json
{
 "providers": {
  "nvidia": {
   "api_key": "${NVIDIA_API_KEY}"
  }
 }
}
```

- Weitere Infos: [Nvidia Model Doku](https://opencode.ai/docs/models/)

**Gesamtanzahl Modelle:** 32

**Letztes Update:** 2026-01-30

### Kategorien & Modelle

- **Meta Llama** (6 Modelle):
  - meta/llama3-70b-instruct
  - meta/llama3-8b-instruct
  - meta/llama2-70b-chat
  - meta/llama2-13b-chat
  - meta/llama2-7b-chat
  - meta/llama-guard-2-8b

- **NVIDIA Nemotron** (6 Modelle):
  - nvidia/nemotron-4-340b-chat
  - nvidia/nemotron-4-340b-4bit
  - nvidia/nemotron-4-340b-fp8
  - nvidia/nemotron-4-340b-instruct
  - nvidia/nemotron-3-8b-base
  - nvidia/nemotron-3-8b-instruct

- **Microsoft Phi** (4 Modelle):
  - microsoft/phi-3-medium-128k-instruct
  - microsoft/phi-3-mini-128k-instruct
  - microsoft/phi-2
  - microsoft/phi-1_5

- **Mistral AI** (5 Modelle):
  - mistralai/mixtral-8x22b-instruct-v0.1
  - mistralai/mixtral-8x7b-instruct-v0.1
  - mistralai/mistral-large-latest
  - mistralai/mistral-medium-latest
  - mistralai/mistral-small-latest

- **Qwen** (4 Modelle):
  - qwen/qwen2-72b-instruct
  - qwen/qwen2-7b-instruct
  - qwen/qwen1.5-72b-chat
  - qwen/qwen1.5-14b-chat

- **Moonshot Kimi** (3 Modelle):
  - moonshot-ai/moonshot-v1-128k
  - moonshot-ai/moonshot-v1-32k
  - moonshot-ai/moonshot-v1-8k

- **DeepSeek** (4 Modelle):
  - deepseek-ai/deepseek-coder-33b-instruct
  - deepseek-ai/deepseek-coder-6.7b-instruct
  - deepseek-ai/deepseek-llm-67b-chat
  - deepseek-ai/deepseek-llm-7b-chat

<details>
<summary>Vollst√§ndige Modellliste (Referenz)</summary>

**Meta Llama:**

- meta/llama3-70b-instruct
- meta/llama3-8b-instruct
- meta/llama2-70b-chat
- meta/llama2-13b-chat
- meta/llama2-7b-chat
- meta/llama-guard-2-8b

**NVIDIA Nemotron:**

- nvidia/nemotron-4-340b-chat
- nvidia/nemotron-4-340b-4bit
- nvidia/nemotron-4-340b-fp8
- nvidia/nemotron-4-340b-instruct
- nvidia/nemotron-3-8b-base
- nvidia/nemotron-3-8b-instruct

**Microsoft Phi:**

- microsoft/phi-3-medium-128k-instruct
- microsoft/phi-3-mini-128k-instruct
- microsoft/phi-2
- microsoft/phi-1_5

**Mistral AI:**

- mistralai/mixtral-8x22b-instruct-v0.1
- mistralai/mixtral-8x7b-instruct-v0.1
- mistralai/mistral-large-latest
- mistralai/mistral-medium-latest
- mistralai/mistral-small-latest

**Qwen:**

- qwen/qwen2-72b-instruct
- qwen/qwen2-7b-instruct
- qwen/qwen1.5-72b-chat
- qwen/qwen1.5-14b-chat

**Moonshot Kimi:**

- moonshot-ai/moonshot-v1-128k
- moonshot-ai/moonshot-v1-32k
- moonshot-ai/moonshot-v1-8k

**DeepSeek:**

- deepseek-ai/deepseek-coder-33b-instruct
- deepseek-ai/deepseek-coder-6.7b-instruct
- deepseek-ai/deepseek-llm-67b-chat
- deepseek-ai/deepseek-llm-7b-chat

</details>

### Vollst√§ndige Modellliste (nach Kategorie)

**Meta Llama:**

- meta/llama3-70b-instruct
- meta/llama3-8b-instruct
- meta/llama2-70b-chat
- meta/llama2-13b-chat
- meta/llama2-7b-chat
- meta/llama-guard-2-8b

**NVIDIA Nemotron:**

- nvidia/nemotron-4-340b-chat
- nvidia/nemotron-4-340b-4bit
- nvidia/nemotron-4-340b-fp8
- nvidia/nemotron-4-340b-instruct
- nvidia/nemotron-3-8b-base
- nvidia/nemotron-3-8b-instruct

**Microsoft Phi:**

- microsoft/phi-3-medium-128k-instruct
- microsoft/phi-3-mini-128k-instruct
- microsoft/phi-2
- microsoft/phi-1_5

**Mistral AI:**

- mistralai/mixtral-8x22b-instruct-v0.1
- mistralai/mixtral-8x7b-instruct-v0.1
- mistralai/mistral-large-latest
- mistralai/mistral-medium-latest
- mistralai/mistral-small-latest

**Qwen:**

- qwen/qwen2-72b-instruct
- qwen/qwen2-7b-instruct
- qwen/qwen1.5-72b-chat
- qwen/qwen1.5-14b-chat

**Moonshot Kimi:**

- moonshot-ai/moonshot-v1-128k
- moonshot-ai/moonshot-v1-32k
- moonshot-ai/moonshot-v1-8k

**DeepSeek:**

- deepseek-ai/deepseek-coder-33b-instruct
- deepseek-ai/deepseek-coder-6.7b-instruct
- deepseek-ai/deepseek-llm-67b-chat
- deepseek-ai/deepseek-llm-7b-chat

### Empfehlungen

- **Best Overall:** meta/llama3-70b-instruct ‚Äì Sehr leistungsf√§hig f√ºr allgemeine Aufgaben, hohe Genauigkeit.
- **Best for Coding:** deepseek-ai/deepseek-coder-33b-instruct ‚Äì Optimiert f√ºr Programmieraufgaben und Codeverst√§ndnis.
- **Best for Long Context:** moonshot-ai/moonshot-v1-128k ‚Äì Unterst√ºtzt sehr lange Kontexte, ideal f√ºr gro√üe Dokumente.
- **Best for Vision:** nvidia/nemotron-4-340b-instruct ‚Äì Unterst√ºtzt multimodale Aufgaben (Text+Bild), hohe Kapazit√§t.
- **Best for Speed:** microsoft/phi-3-mini-128k-instruct ‚Äì Sehr schnelle Inferenz, geeignet f√ºr Echtzeitanwendungen.

### Integration in OpenCode

1. F√ºge den Provider `nvidia` in deiner `opencode.json` hinzu (siehe oben).
2. Setze die Umgebungsvariable `NVIDIA_API_KEY` mit deinem Schl√ºssel.
3. Modelle k√∂nnen in OpenCode-Plugins und Agenten als Provider ausgew√§hlt werden.
4. Weitere Details und Modelloptionen findest du unter [opencode.ai/docs/models/](https://opencode.ai/docs/models/).

---

## Best Practices

- Immer den vorgesehenen Installer oder CLI-Befehl nutzen, falls vom Agenten/Plugin bereitgestellt (z.B. `bunx ... install`).
- Schritte zum Kopieren von Agenten/Skills nie √ºberspringen.
- Registrierung des Agenten in Konfigurationsdateien immer best√§tigen.
- Nach der Installation immer pr√ºfen:
  - `opencode agents list`
  - `opencode doctor`
  - Testlauf mit minimalem Prompt
- Nach der Installation je nach Agentenfunktion per CLI/API/Health-Check oder UI verifizieren.

## Beispielprozess f√ºr Agenten mit Oh-My-OpenCode

1. Plugin installieren: `bunx oh-my-opencode install`
2. Installationsabfragen beantworten (Abos, Provider, Agentenpr√§ferenzen).
3. CLI registriert Agenten und Skills (siehe Plugin-Dokumentation f√ºr Struktur).
4. Pr√ºfen, ob der Agent in `~/.config/opencode/opencode.json` oder der Projektkonfiguration gelistet ist.
5. Provider ggf. per `opencode auth login` oder √§hnlichem CLI-Befehl authentifizieren.
6. Agenten mit Beispielaufruf, Plan oder Health-Check testen.

---

## üß† Strategischer Hinweis: Agent Lifecycle Management

Langfristig empfiehlt sich ein Abschnitt zu ‚ÄûAgent Lifecycle Management‚Äú:

- Installation
- Registrierung
- Aktivierung
- Update
- Deaktivierung
- Entfernung

Das Dokument kann so zu einem vollst√§ndigen Guide f√ºr das Management von Agenten ausgebaut werden.

Dieses Dokument sollte aktualisiert werden, wenn Agenten in diesem Workspace hinzugef√ºgt oder entfernt werden.

---
